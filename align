#!/usr/bin/env python
import optparse, pdb, math, operator
from decimal import Decimal
import sys
from collections import defaultdict

optparser = optparse.OptionParser()
optparser.add_option("-d", "--data",
                     dest="train",
                     default="data/hansards",
                     help="Data filename prefix (default=data)")
optparser.add_option("-e", "--english",
                     dest="english",
                     default="e",
                     help="Suffix of English filename (default=e)")
optparser.add_option("-f", "--french",
                     dest="french",
                     default="f",
                     help="Suffix of French filename (default=f)")
optparser.add_option("-t", "--threshold",
                     dest="threshold",
                     default=0.5, type="float",
                     help="Threshold for aligning (default=0.5)")
optparser.add_option("-n", "--num_sentences",
                     dest="num_sents",
                     default=sys.maxint, type="int",
                     help="Number of sentences to train and align")

(opts, _) = optparser.parse_args()
f_data = "%s.%s" % (opts.train, opts.french)
e_data = "%s.%s" % (opts.train, opts.english)

sys.stderr.write("Training via IBM 1...")
bitext = [[sentence.strip().split() for sentence in pair]
          for pair in zip(open(f_data), open(e_data))[:opts.num_sents]]

converge = False

f_count = defaultdict(int)
t = defaultdict(Decimal)
for (n, (f,e)) in enumerate(bitext):
    for f_i in set(f):
        f_count[f_i] = 0

for (n, (f,e)) in enumerate(bitext):
    for f_i in set(f):
        for e_j in set(e):
            t[(f_i, e_j)] = 1.0 / len(f_count)


e_count = defaultdict(int)
fe_count = defaultdict(int)
s = defaultdict(Decimal)
tot_fe_count = 0.0
tot_f = defaultdict(float)

for (n, (f, e)) in enumerate(bitext):
    print n
    for f_i in set(f):
        t[f_i] = 0
        f_count[f_i] += 1
        for e_j in set(e):
            fe_count[(f_i, e_j)] += 1
            tot_fe_count += 1
            s[(f_i, e_j)] = 0
    for e_j in set(e):
        e_count[e_j] += 1
    if n % 100 == 0:
        sys.stderr.write(".")

    #Normalization
    for key in fe_count:
        fe_count[key] = fe_count[key] / tot_fe_count
        s[key] += fe_count[key]
x = 0

while not converge:

    print x

    for (n, (f, e)) in enumerate(bitext):
        #Collecting counts
        e = set(e)
        f = set(f)
        for e_j in e:
            for f_i in f:
                fe_count[(f_i, e_j)] += t[(f_i, e_j)] / (s[(f_i, e_j)])
                tot_f[f_i] += t[(f_i, e_j)] / (s[(f_i, e_j)])

        #estimate probabilities
        for f_i in f:
            for e_j in e:
                t[(f_i, e_j)] = fe_count[(f_i, e_j)] / tot_f[f_i]

    if max(t.iteritems(), key=operator.itemgetter(1))[1] >= opts.threshold:
        converge = True
    x += 1
pdb.set_trace()





'''
dice = defaultdict(int)
for (k, (f_i, e_j)) in enumerate(fe_count.keys()):
    dice[(f_i, e_j)] = 2.0 * fe_count[(f_i, e_j)] / (f_count[f_i] + e_count[e_j])
    if k % 5000 == 0:
        sys.stderr.write(".")
sys.stderr.write("\n")

for (f, e) in bitext:
    for (i, f_i) in enumerate(f):
        for (j, e_j) in enumerate(e):
            if dice[(f_i, e_j)] >= opts.threshold:
                sys.stdout.write("%i-%i " % (i, j))
    sys.stdout.write("\n")
'''
