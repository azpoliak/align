#!/usr/bin/env python
import optparse, subprocess
from subprocess import check_output
import operator
import sys, pdb, math
from collections import defaultdict
from multiprocessing import Pool, Process
# import multiprocessing.pool import ThreadPool

def sorte(t):
    return sorted(t.items(), key=operator.itemgetter(1))

def train(f_vocab, e_vocab, bitext):

    f_count = defaultdict(int)
    e_count = defaultdict(int)
    fe_count = defaultdict(int)
    total_e = defaultdict(float)
    s_total = defaultdict(float)
    t = defaultdict(float)
    #uniform probabilities
    for f_i in f_vocab:
        for e_j in e_vocab:
            t[(f_i,e_j)] = 1 / float(len(e_vocab))

    sys.stderr.write("Start...")

    for _ in range(10):
        for e_j in e_vocab:
            for f_i in f_vocab:
                fe_count[(f_i,e_j)] = 0
        for e_j in e_vocab:
            total_e[f_i] = 0


        for (n, (f, e)) in enumerate(bitext):
            #normalization
            for e_j in e:
                s_total[e_j] = 0
                for f_i in f:
                    s_total[e_j] += t[(f_i,e_j)]
            #collect counts
            for e_j in e:
                for f_i in f:
                    if s_total[e_j] == 0:
                        pdb.set_trace()
                    fe_count[(f_i, e_j)] += t[(f_i, e_j)] / float(s_total[e_j])
                    total_e[f_i] += t[(f_i, e_j)] / float(s_total[e_j])

        #estimate probabilities
        for f_i in f_vocab:
            for e_j in e_vocab:
                t[(f_i, e_j)] = fe_count[(f_i, e_j)] / total_e[f_i]

    return t

def smart_merge_divide(fe, ef, j, i):
    return ((fe + ef) / (math.fabs(j - i) + 1))


def make_bitext(a_data, b_data, num_sents):
    return [[sentence.strip().split() for sentence in pair]
            for pair in zip(open(a_data), open(b_data))[:num_sents]]

# def make_t(a_vocab, b_vocab, ab_bitext, num_sents):
#

def main():

    optparser = optparse.OptionParser()
    optparser.add_option("-d", "--data", dest="train", default="data/hansards", help="Data filename prefix (default=data)")
    optparser.add_option("-e", "--english", dest="english", default="e", help="Suffix of English filename (default=e)")
    optparser.add_option("-f", "--french", dest="french", default="f", help="Suffix of French filename (default=f)")
    optparser.add_option("-t", "--threshold", dest="threshold", default=0.5, type="float", help="Threshold for aligning with Dice's coefficient (default=0.5)")
    optparser.add_option("-p", "--poolsize", dest="pool_size", default=4, type="int", help="Number of processes to use")
    optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to use for training and alignment")
    (opts, _) = optparser.parse_args()
    f_data = "%s.%s" % (opts.train, opts.french)
    e_data = "%s.%s" % (opts.train, opts.english)

    sys.stderr.write("Training with IBM Model 1...")

    pool = Pool(processes=opts.pool_size)

    fe_bitext_handler = pool.apply_async(make_bitext, (f_data, e_data, opts.num_sents,))
    ef_bitext_handler = pool.apply_async(make_bitext, (e_data, f_data, opts.num_sents,))

    fe_bitext = fe_bitext_handler.get()
    ef_bitext = ef_bitext_handler.get()

    f_count = defaultdict(int)
    e_count = defaultdict(int)
    fe_count = defaultdict(int)
    total_e = defaultdict(float)
    s_total = defaultdict(float)
    t = defaultdict(float)
    f_vocab = set()
    e_vocab = set()

    f_length, e_length = 0,0
    for x in range(opts.num_sents):
        sent = [sent for sent in fe_bitext[x]]
        f_vocab.update(set(sent[0]))
        e_vocab.update(set(sent[1]))

    pool = Pool(processes=opts.pool_size)

    t1_handler = pool.apply_async(train, (f_vocab, e_vocab, fe_bitext,))
    t2_handler = pool.apply_async(train, (e_vocab, f_vocab, ef_bitext,))

    t1 = t1_handler.get()
    t2 = t2_handler.get()

    for (f, e) in fe_bitext:
        for (i, f_i) in enumerate(f):
            best = [[], '', 0.0]
            for (j, e_j) in enumerate(e):
                curr = smart_merge_divide(t1[(f_i, e_j)], t2[(e_j, f_i)], i, j)
                if curr > best[2]:
                    best[2] =  curr
                    best[1] = e_j
                    best[0] = [j]
                elif t1[(f_i, e_j)] == best[2]:
                    best[0].append(j)
            found = False
            diffs = best[0]
            for x in range(len(diffs)):
                sys.stdout.write("%i-%i " % (i, diffs[x]))
        sys.stdout.write("\n")


if __name__ == '__main__':
    main()
